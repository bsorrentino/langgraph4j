package org.bsc.langgraph4j.spring.ai.agentexecutor;

import org.springframework.ai.chat.model.ChatModel;
import org.springframework.ai.ollama.OllamaChatModel;
import org.springframework.ai.ollama.api.OllamaApi;
import org.springframework.ai.ollama.api.OllamaOptions;
import org.springframework.ai.openai.OpenAiChatModel;
import org.springframework.ai.openai.OpenAiChatOptions;
import org.springframework.ai.openai.api.OpenAiApi;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Profile;

@Configuration
public class ChatModelConfiguration {

	@Bean
	@Profile("ollama")
	public ChatModel ollamaModel() {
		return OllamaChatModel.builder()
			.ollamaApi(new OllamaApi("http://localhost:11434"))
			.defaultOptions(OllamaOptions.builder().model("qwen2.5:7b").temperature(0.1).build())
			.build();
	}

	@Bean
	@Profile("openai")
	public ChatModel openaiModel() {
		return OpenAiChatModel.builder()
			.openAiApi(OpenAiApi.builder()
				.baseUrl("https://api.openai.com")
				.apiKey(System.getenv("OPENAI_API_KEY"))
				.build())
			.defaultOptions(OpenAiChatOptions.builder().model("gpt-4o-mini").logprobs(false).temperature(0.1).build())
			.build();

	}

}
